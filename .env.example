NODE_ENV=development
PORT=3001
API_URL=http://localhost:3001

# LLM Provider API Keys
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-3.5-turbo

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral:latest

GROQ_API_KEY=gsk_...
GROQ_MODEL=llama-3.1-8b-instant

ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Langfuse Configuration (Optional)
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key_here
LANGFUSE_SECRET_KEY=your_langfuse_secret_key_here
LANGFUSE_BASE_URL=https://cloud.langfuse.com

# Memory System Configuration
# Neo4j Configuration (Episodic Memory)
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password_here
NEO4J_DATABASE=clear-ai

# Pinecone Configuration (Semantic Memory)
PINECONE_API_KEY=pcsk_...
PINECONE_ENVIRONMENT=us-east-1-aws
PINECONE_INDEX_NAME=clear-ai

# Memory System Settings
MEMORY_EMBEDDING_MODEL=nomic-embed-text
MEMORY_EMBEDDING_DIMENSIONS=768
MEMORY_MAX_CONTEXT_MEMORIES=50
MEMORY_SIMILARITY_THRESHOLD=0.7

# Memory cleanup settings
MEMORY_CLEANUP_ENABLED=true
MEMORY_CLEANUP_INTERVAL_HOURS=24
MEMORY_MAX_AGE_DAYS=90

# Semantic Extraction Configuration
SEMANTIC_EXTRACTION_ENABLED=true
SEMANTIC_EXTRACTION_MIN_CONFIDENCE=0.7
SEMANTIC_EXTRACTION_MAX_CONCEPTS=3
SEMANTIC_EXTRACTION_RELATIONSHIPS=true
SEMANTIC_EXTRACTION_CATEGORIES=AI,Technology,Programming,Science,General
SEMANTIC_EXTRACTION_BATCH_SIZE=5

# Embedding Provider for Semantic Memory (Pinecone)
MEMORY_EMBEDDING_PROVIDER=openai  # Options: 'ollama' (local), 'openai' (production)
